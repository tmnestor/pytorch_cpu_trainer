# Make executable
chmod +x run.py

# Run training
./run.py --mode train --config config.yaml

# Run inference
./run.py --mode inference --config config.yaml


python run_trainer.py --mode train --config config.yaml

# Instead of running the file directly:
# python pytorch_cpu_trainer.py

# Run using the module approach:
python -m pytorch_cpu_trainer.pytorch_cpu_trainer --mode train --config config.yaml



# First run - uses original defaults
python pytorch_cpu_trainer.py --mode train

# Second run - automatically uses averaged best parameters from history
python pytorch_cpu_trainer.py --mode train

# Force retrain with new defaults
python pytorch_cpu_trainer.py --mode train --retrain



# Check contents of model_history.db
sqlite3 checkpoints/model_history.db

# Once in SQLite prompt, run these commands:
# Show all tables
.tables

# Show table schema
.schema model_experiments

# View all experiments, ordered by performance
SELECT 
    datetime(timestamp) as date,
    metric_value as score,
    json_extract(architecture, '$.hidden_layers') as layers,
    json_extract(hyperparameters, '$.learning_rate') as lr,
    json_extract(hyperparameters, '$.dropout_rate') as dropout
FROM model_experiments 
ORDER BY metric_value DESC;

# View best result only
SELECT 
    datetime(timestamp) as date,
    metric_value as score,
    json_extract(architecture, '$.hidden_layers') as layers,
    json_extract(hyperparameters, '$.learning_rate') as lr
FROM model_experiments 
ORDER BY metric_value DESC 
LIMIT 1;

# Exit SQLite
.quit